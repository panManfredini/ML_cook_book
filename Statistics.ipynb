{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats\n",
    "\n",
    "- F-statistic\n",
    "- t-student test and studentizing residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF (Probability mass function) CDF and SF\n",
    "- [https://en.wikipedia.org/wiki/Probability_mass_function](pmf)\n",
    "- Is the discrete pdf for discrete random variables, like poisson or binomial.\n",
    "- is the prob to obtain n_obs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4602053813064103\n",
      "0.4602053813064103\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.binom.pmf(50,100,0.5) # obs = 10, trial=100, prob = 0.5\n",
    "print(stats.binom.sf(50,100,0.5)) # obs = 10, trial=100, prob = 0.5\n",
    "print(1- stats.binom.cdf(50,100,0.5)) # obs = 10, trial=100, prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for cdf VS sf, the survial function is defined as (1-CDF(k)) this means that in a discrete random var is not the p-value, but is (1-CDF(k-1)) and so SF(k-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Model Regression\n",
    "\n",
    "### Error on the Fit\n",
    "\n",
    "Since tipically one does not have the error on the measures, then cannot do chisquare test to evaluate best fit (is that true?)\n",
    "\n",
    "Then one uses another mesure:\n",
    "\n",
    "SSE (sum of square error)  = $\\sum^m_i (y(x_i) - y^i_{obs})^2$ \n",
    "\n",
    "TSE (total sum of squares) = $\\sum^m_i (\\bar{y_{obs}} - y^i_{obs})^2$\n",
    "\n",
    "Goodness $R^2 = 1 - \\frac{SSE}{TSE}$\n",
    "\n",
    "Now TSE is just the difference with a horizontal line at the mean, the $y$ are not taken from same population (not same random variable, is linear interpolation) so this is basically the worst variance you can get, **except for a horizontal line model**. SSE is basically the variance, except that they are not distributed as same random var. If you divide SSE by $\\sigma_y$ you obtain a $\\chi^2$ but do you have sigma?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
